# =============================================================================
# êµ¬ê¸€ ì½”ë©ìš©: KFall ë°ì´í„° ë¶„ì„ ë° íŒŒë¼ë¯¸í„° ì¶”ì¶œ
# =============================================================================

import os
import glob
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.fft import fft, fftfreq
import warnings
warnings.filterwarnings('ignore')

# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸
from google.colab import drive
drive.mount('/content/drive')

# =============================================================================
# 1ë‹¨ê³„: ë°ì´í„° ë¡œë”©
# =============================================================================

def load_walking_data(base_path='/content/drive/MyDrive/KFall_dataset/data/walking_data'):
    """KFall ë³´í–‰ ë°ì´í„° ë¡œë”©"""

    walking_activities = ['06', '07', '08', '09', '10', '35', '36']
    all_data = []

    # ëª¨ë“  í”¼í—˜ì í´ë” íƒìƒ‰
    for subject_folder in glob.glob(os.path.join(base_path, 'SA*')):
        subject_id = os.path.basename(subject_folder)

        # CSV íŒŒì¼ë“¤ íƒìƒ‰
        for csv_file in glob.glob(os.path.join(subject_folder, '*.csv')):
            filename = os.path.basename(csv_file)
            try:
                activity_num = filename.split('T')[1][:2]
                if activity_num in walking_activities:
                    df = pd.read_csv(csv_file)
                    df['subject_id'] = subject_id
                    df['activity_num'] = activity_num
                    all_data.append(df)
            except:
                continue

    if all_data:
        combined_df = pd.concat(all_data, ignore_index=True)
        print(f"âœ… {len(all_data)}ê°œ íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
        print(f"ğŸ“Š í”¼í—˜ì: {combined_df['subject_id'].nunique()}ëª…")
        print(f"ğŸš¶ í™œë™ ì¢…ë¥˜: {sorted(combined_df['activity_num'].unique())}")
        return combined_df
    else:
        print("âŒ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None

# =============================================================================
# 2ë‹¨ê³„: íŠ¹ì§• ì¶”ì¶œ ë° ë¶„ì„
# =============================================================================

def extract_walking_features(data):
    """ë³´í–‰ íŠ¹ì§• ì¶”ì¶œ"""

    def analyze_file_group(df_group):
        # ê°€ì†ë„ ë²¡í„° í¬ê¸°
        acc_mag = np.sqrt(df_group['AccX']**2 + df_group['AccY']**2 + df_group['AccZ']**2)
        gyr_mag = np.sqrt(df_group['GyrX']**2 + df_group['GyrY']**2 + df_group['GyrZ']**2)

        # ì´ë™í‰ê·  í•„í„°ë§
        acc_smooth = np.convolve(acc_mag, np.ones(5)/5, mode='same')

        # í”¼í¬ ê²€ì¶œ
        threshold = np.mean(acc_smooth) + 0.3 * np.std(acc_smooth)
        peaks = []
        for i in range(5, len(acc_smooth)-5):
            if acc_smooth[i] > threshold and acc_smooth[i] == max(acc_smooth[i-5:i+6]):
                peaks.append(i)

        # íŠ¹ì§• ê³„ì‚°
        features = {
            'acc_mean': np.mean(acc_mag),
            'acc_std': np.std(acc_mag),
            'gyr_mean': np.mean(gyr_mag),
            'peak_count': len(peaks)
        }

        # ë³´í–‰ ì£¼ê¸° ë¶„ì„
        if len(peaks) > 1:
            time_stamps = df_group['TimeStamp(s)'].values
            peak_times = time_stamps[peaks]
            intervals = np.diff(peak_times)
            features['step_frequency'] = 1.0 / np.mean(intervals)
            features['step_regularity'] = 1.0 / (1.0 + np.std(intervals))
        else:
            features['step_frequency'] = 0
            features['step_regularity'] = 0

        return features

    # ëª¨ë“  íŒŒì¼ ë¶„ì„
    results = []
    grouped = data.groupby(['subject_id', 'activity_num'])

    for (subject, activity), group in grouped:
        # íŒŒì¼ë³„ë¡œ ë¶„ë¦¬ (ê°™ì€ subject+activityë„ ì—¬ëŸ¬ íŒŒì¼ ê°€ëŠ¥)
        for file_group in [group]:  # ì‹¤ì œë¡œëŠ” ë” ì„¸ë¶„í™” í•„ìš”ì‹œ ì¶”ê°€
            features = analyze_file_group(file_group)
            features['subject_id'] = subject
            features['activity_num'] = activity
            results.append(features)

    return pd.DataFrame(results)

# =============================================================================
# 3ë‹¨ê³„: ìµœì  íŒŒë¼ë¯¸í„° ê³„ì‚°
# =============================================================================

def calculate_optimal_parameters(features_df):
    """ë³´í–‰ ê°ì§€ìš© ìµœì  íŒŒë¼ë¯¸í„° ê³„ì‚°"""

    # ê¸°ë³¸ í†µê³„
    params = {
        'acc_mean_min': features_df['acc_mean'].quantile(0.1),
        'acc_mean_max': features_df['acc_mean'].quantile(0.9),
        'acc_std_min': features_df['acc_std'].quantile(0.2),
        'step_freq_min': 1.0,
        'step_freq_max': 4.0,
        'regularity_min': features_df['step_regularity'].quantile(0.3),
        'confidence_threshold': 0.6
    }

    print("ğŸ¯ ìµœì  íŒŒë¼ë¯¸í„°:")
    for key, value in params.items():
        print(f"   {key}: {value:.3f}")

    return params

# =============================================================================
# 4ë‹¨ê³„: ì‹œê°í™”
# =============================================================================

def visualize_patterns(features_df):
    """ë³´í–‰ íŒ¨í„´ ì‹œê°í™”"""

    plt.figure(figsize=(12, 8))

    # í™œë™ë³„ ê°€ì†ë„ íŒ¨í„´
    plt.subplot(2, 2, 1)
    sns.boxplot(data=features_df, x='activity_num', y='acc_mean')
    plt.title('í™œë™ë³„ í‰ê·  ê°€ì†ë„')

    # ë³´í–‰ ì£¼íŒŒìˆ˜
    plt.subplot(2, 2, 2)
    sns.boxplot(data=features_df, x='activity_num', y='step_frequency')
    plt.title('í™œë™ë³„ ë³´í–‰ ì£¼íŒŒìˆ˜')

    # ê°œì¸ì°¨ (ì²˜ìŒ 6ëª…ë§Œ)
    plt.subplot(2, 2, 3)
    sample_subjects = features_df['subject_id'].unique()[:6]
    sample_data = features_df[features_df['subject_id'].isin(sample_subjects)]
    sns.boxplot(data=sample_data, x='subject_id', y='acc_mean')
    plt.title('ê°œì¸ë³„ ì°¨ì´')
    plt.xticks(rotation=45)

    # íŠ¹ì§• ë¶„í¬
    plt.subplot(2, 2, 4)
    plt.scatter(features_df['acc_mean'], features_df['step_frequency'],
                c=features_df['activity_num'].astype('category').cat.codes, alpha=0.6)
    plt.xlabel('í‰ê·  ê°€ì†ë„')
    plt.ylabel('ë³´í–‰ ì£¼íŒŒìˆ˜')
    plt.title('íŠ¹ì§• ë¶„í¬')

    plt.tight_layout()
    plt.show()

# =============================================================================
# 5ë‹¨ê³„: ë¼ì¦ˆë² ë¦¬íŒŒì´ ì½”ë“œ ìƒì„±
# =============================================================================

def generate_raspberry_code(params):
    """ë¼ì¦ˆë² ë¦¬íŒŒì´ìš© ì½”ë“œ ìƒì„± (ì½”ë© ë¶„ì„ ê²°ê³¼ ë°˜ì˜)"""

    code_template = f'''# ë¼ì¦ˆë² ë¦¬íŒŒì´ìš© ì‹¤ì‹œê°„ ë³´í–‰ ê°ì§€ê¸°
# ğŸ¯ KFall ë°ì´í„°ì…‹ ë¶„ì„ ê²°ê³¼ ì ìš©ë¨
import numpy as np
from collections import deque
import time

class WalkingDetector:
    def __init__(self):
        # ë°ì´í„° ë²„í¼ (2ì´ˆ = 200ìƒ˜í”Œ @ 100Hz)
        self.buffer_size = 200
        self.acc_buffer = deque(maxlen=self.buffer_size)
        self.time_buffer = deque(maxlen=self.buffer_size)

        # ë³´í–‰ ìƒíƒœ
        self.is_walking = False
        self.confidence = 0.0

        # ğŸ”¥ ì½”ë© ë¶„ì„ìœ¼ë¡œ ìµœì í™”ëœ ì„ê³„ê°’ (ì‹¤ì œ KFall ë°ì´í„° ê¸°ë°˜)
        self.thresholds = {{
            'acc_mean_min': {params['acc_mean_min']:.3f},
            'acc_mean_max': {params['acc_mean_max']:.3f},
            'acc_std_min': {params['acc_std_min']:.3f},
            'step_freq_min': {params['step_freq_min']:.1f},
            'step_freq_max': {params['step_freq_max']:.1f},
            'regularity_min': {params['regularity_min']:.3f},
            'confidence_min': {params['confidence_threshold']:.1f}
        }}

        print("ğŸ¯ KFall ìµœì í™” íŒŒë¼ë¯¸í„° ë¡œë“œë¨:")
        for key, value in self.thresholds.items():
            print(f"   {{key}}: {{value}}")

    def add_data(self, acc_x, acc_y, acc_z, timestamp):
        """ìƒˆ ì„¼ì„œ ë°ì´í„° ì¶”ê°€"""
        acc_magnitude = np.sqrt(acc_x**2 + acc_y**2 + acc_z**2)

        self.acc_buffer.append(acc_magnitude)
        self.time_buffer.append(timestamp)

        # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë¶„ì„
        if len(self.acc_buffer) >= self.buffer_size:
            self._analyze()

        return self.is_walking, self.confidence

    def _analyze(self):
        """ë³´í–‰ ë¶„ì„"""
        acc_data = np.array(self.acc_buffer)
        time_data = np.array(self.time_buffer)

        # ì´ë™í‰ê·  í•„í„°ë§
        acc_smooth = np.convolve(acc_data, np.ones(5)/5, mode='same')

        # ê¸°ë³¸ íŠ¹ì§•
        acc_mean = np.mean(acc_data)
        acc_std = np.std(acc_data)

        # í”¼í¬ ê²€ì¶œ
        threshold = np.mean(acc_smooth) + 0.3 * np.std(acc_smooth)
        peaks = []
        for i in range(5, len(acc_smooth)-5):
            if acc_smooth[i] > threshold and acc_smooth[i] == max(acc_smooth[i-5:i+6]):
                peaks.append(i)

        # ë³´í–‰ ì£¼ê¸° ê³„ì‚°
        step_frequency = 0
        regularity = 0
        if len(peaks) > 1:
            peak_times = time_data[peaks]
            intervals = np.diff(peak_times)
            if len(intervals) > 0:
                step_frequency = 1.0 / np.mean(intervals)
                regularity = 1.0 / (1.0 + np.std(intervals))

        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = 0.0

        if self.thresholds['acc_mean_min'] <= acc_mean <= self.thresholds['acc_mean_max']:
            confidence += 0.3
        if acc_std >= self.thresholds['acc_std_min']:
            confidence += 0.3
        if self.thresholds['step_freq_min'] <= step_frequency <= self.thresholds['step_freq_max']:
            confidence += 0.4

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        self.confidence = confidence
        self.is_walking = confidence >= self.thresholds['confidence_min']

    def get_status(self):
        """í˜„ì¬ ìƒíƒœ ë°˜í™˜"""
        return {{
            'walking': self.is_walking,
            'confidence': self.confidence
        }}

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    detector = WalkingDetector()

    # ì„¼ì„œ ë°ì´í„° ë£¨í”„ (êµ¬í˜„ í•„ìš”)
    while True:
        # IMU ì„¼ì„œì—ì„œ ë°ì´í„° ì½ê¸°
        acc_x, acc_y, acc_z = read_imu_data()  # ì‹¤ì œ ì„¼ì„œ í•¨ìˆ˜ë¡œ êµì²´
        timestamp = time.time()

        # ë³´í–‰ ê°ì§€
        walking, confidence = detector.add_data(acc_x, acc_y, acc_z, timestamp)

        if walking:
            print(f"ğŸš¶ ë³´í–‰ ì¤‘ (ì‹ ë¢°ë„: {{confidence:.2f}})")

        time.sleep(0.01)  # 100Hz
'''

    return code_template

# =============================================================================
# ì „ì²´ ì‹¤í–‰ í•¨ìˆ˜
# =============================================================================

def run_complete_analysis():
    """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""

    print("ğŸš€ KFall ë³´í–‰ ê°ì§€ ì‹œìŠ¤í…œ ë¶„ì„ ì‹œì‘")
    print("="*50)

    # 1ë‹¨ê³„: ë°ì´í„° ë¡œë”©
    print("\n1ï¸âƒ£ ë°ì´í„° ë¡œë”©...")
    data = load_walking_data()
    if data is None:
        return

    # 2ë‹¨ê³„: íŠ¹ì§• ì¶”ì¶œ
    print("\n2ï¸âƒ£ íŠ¹ì§• ì¶”ì¶œ...")
    features_df = extract_walking_features(data)
    print(f"âœ… {len(features_df)}ê°œ ìƒ˜í”Œ ë¶„ì„ ì™„ë£Œ")

    # 3ë‹¨ê³„: íŒŒë¼ë¯¸í„° ìµœì í™”
    print("\n3ï¸âƒ£ íŒŒë¼ë¯¸í„° ìµœì í™”...")
    optimal_params = calculate_optimal_parameters(features_df)

    # 4ë‹¨ê³„: ì‹œê°í™”
    print("\n4ï¸âƒ£ íŒ¨í„´ ì‹œê°í™”...")
    visualize_patterns(features_df)

    # 5ë‹¨ê³„: ë¼ì¦ˆë² ë¦¬íŒŒì´ ì½”ë“œ ìƒì„±
    print("\n5ï¸âƒ£ ë¼ì¦ˆë² ë¦¬íŒŒì´ ì½”ë“œ ìƒì„±...")
    raspberry_code = generate_raspberry_code(optimal_params)

    # íŒŒì¼ ì €ì¥
    with open('/content/drive/MyDrive/KFall_dataset/data/walking_data/walking_detector_raspberry.py', 'w', encoding='utf-8') as f:
        f.write(raspberry_code)

    print("âœ… ì™„ë£Œ!")
    print("ğŸ“ ë¼ì¦ˆë² ë¦¬íŒŒì´ ì½”ë“œ: /content/drive/MyDrive/KFall_dataset/data/walking_data/walking_detector_raspberry.py")
    print("ğŸ¯ ì‹¤ì œ KFall ë°ì´í„° ê¸°ë°˜ ìµœì  íŒŒë¼ë¯¸í„°ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!")

    # ì£¼ìš” íŒŒë¼ë¯¸í„° ë‹¤ì‹œ ì¶œë ¥
    print("\nğŸ“Š ì ìš©ëœ ì£¼ìš” íŒŒë¼ë¯¸í„°:")
    print(f"   í‰ê·  ê°€ì†ë„ ë²”ìœ„: {optimal_params['acc_mean_min']:.3f} ~ {optimal_params['acc_mean_max']:.3f}")
    print(f"   ë³´í–‰ ì£¼íŒŒìˆ˜ ë²”ìœ„: {optimal_params['step_freq_min']:.1f} ~ {optimal_params['step_freq_max']:.1f} Hz")
    print(f"   ì‹ ë¢°ë„ ì„ê³„ê°’: {optimal_params['confidence_threshold']:.1f}")

    return features_df, optimal_params

# =============================================================================
# ì‹¤í–‰
# =============================================================================

# ì „ì²´ ë¶„ì„ ì‹¤í–‰
results = run_complete_analysis()