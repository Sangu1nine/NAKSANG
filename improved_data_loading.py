# =============================================================================
# ê°œì„ ëœ ë°ì´í„° ë¡œë”©: sensor_dataì—ì„œ ë°”ë¡œ ì²˜ë¦¬
# ðŸš€ ë³„ë„ ì¶”ì¶œ ì—†ì´ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬
# =============================================================================

import os
import glob
import pandas as pd
import numpy as np
import re
from pathlib import Path

def load_data_directly_from_sensor(base_path='/content/drive/MyDrive/KFall_dataset/data/sensor_data_new'):
    """sensor_dataì—ì„œ ë°”ë¡œ ë³´í–‰/ë¹„ë³´í–‰ ë°ì´í„° ë¡œë”© (ê°œì„ ëœ ë°©ì‹)"""
    
    # í™œë™ ë¶„ë¥˜ ì •ì˜
    activity_mapping = {
        # ë³´í–‰ í™œë™ (Walking = 1)
        'walking': ['06', '07', '08', '09', '10', '35', '36'],
        
        # ë¹„ë³´í–‰ í™œë™ (Non-walking = 0) - ì¼ìƒ í™œë™ë§Œ
        'non_walking': [
            '01', '02', '03', '04', '05',  # ì¼ìƒ í™œë™
            '11', '12', '13', '14', '15',  # ê¸°íƒ€ í™œë™
            '16', '17', '18', '19'         # ê¸°íƒ€ ë¹„ë³´í–‰ í™œë™
        ]
    }
    
    all_data = []
    file_stats = {
        'walking_files': 0,
        'non_walking_files': 0,
        'excluded_fall_files': 0,
        'error_files': 0,
        'total_subjects': set()
    }
    
    print("ðŸ“‚ sensor_dataì—ì„œ ì§ì ‘ ë¡œë”© ì‹œìž‘...")
    
    # ëª¨ë“  í”¼í—˜ìž í´ë” íƒìƒ‰ (SA06~SA38, SA34 ì œì™¸)
    for subject_num in range(6, 39):
        if subject_num == 34:  # SA34 ì œì™¸
            continue
            
        subject_id = f'SA{subject_num:02d}'
        subject_folder = os.path.join(base_path, subject_id)
        
        if not os.path.exists(subject_folder):
            continue
            
        file_stats['total_subjects'].add(subject_id)
        
        # CSV íŒŒì¼ë“¤ íƒìƒ‰
        csv_files = glob.glob(os.path.join(subject_folder, '*.csv'))
        
        for csv_file in csv_files:
            filename = os.path.basename(csv_file)
            
            try:
                # íŒŒì¼ëª…ì—ì„œ Task ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: S06T06R01.csv â†’ 06)
                t_match = re.search(r'T(\d+)', filename)
                if not t_match:
                    continue
                    
                activity_num = t_match.group(1)
                
                # í™œë™ ë¶„ë¥˜
                if activity_num in activity_mapping['walking']:
                    label = 1  # ë³´í–‰
                    activity_type = 'walking'
                    file_stats['walking_files'] += 1
                elif activity_num in activity_mapping['non_walking']:
                    label = 0  # ë¹„ë³´í–‰
                    activity_type = 'non_walking'
                    file_stats['non_walking_files'] += 1
                elif int(activity_num) >= 20 and int(activity_num) <= 34:
                    # ë‚™ìƒ ê´€ë ¨ í™œë™ ì œì™¸
                    file_stats['excluded_fall_files'] += 1
                    continue
                else:
                    continue  # ì •ì˜ë˜ì§€ ì•Šì€ í™œë™
                
                # CSV íŒŒì¼ ë¡œë”© (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
                try:
                    df = pd.read_csv(csv_file)
                    
                    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ (ë©”ëª¨ë¦¬ ì ˆì•½)
                    required_columns = ['TimeStamp(s)', 'AccX', 'AccY', 'AccZ', 'GyrX', 'GyrY', 'GyrZ']
                    missing_columns = [col for col in required_columns if col not in df.columns]
                    
                    if missing_columns:
                        print(f"âš ï¸ {filename}: ëˆ„ë½ëœ ì»¬ëŸ¼ {missing_columns}")
                        file_stats['error_files'] += 1
                        continue
                    
                    df = df[required_columns].copy()
                    
                    # ë©”íƒ€ë°ì´í„° ì¶”ê°€
                    df['subject_id'] = subject_id
                    df['activity_num'] = activity_num
                    df['label'] = label
                    df['activity_type'] = activity_type
                    df['filename'] = filename
                    
                    all_data.append(df)
                    
                except Exception as e:
                    print(f"âŒ {filename} ë¡œë”© ì‹¤íŒ¨: {e}")
                    file_stats['error_files'] += 1
                    continue
                    
            except Exception as e:
                print(f"âŒ {filename} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                file_stats['error_files'] += 1
                continue
    
    # ê²°ê³¼ í†µí•©
    if all_data:
        combined_df = pd.concat(all_data, ignore_index=True)
        
        print("\nâœ… ë¡œë”© ì™„ë£Œ!")
        print(f"ðŸ“Š ì´ í”¼í—˜ìž: {len(file_stats['total_subjects'])}ëª…")
        print(f"ðŸš¶ ë³´í–‰ íŒŒì¼: {file_stats['walking_files']}ê°œ")
        print(f"ðŸ›‘ ë¹„ë³´í–‰ íŒŒì¼: {file_stats['non_walking_files']}ê°œ")
        print(f"ðŸš« ì œì™¸ëœ ë‚™ìƒ íŒŒì¼: {file_stats['excluded_fall_files']}ê°œ")
        print(f"âŒ ì˜¤ë¥˜ íŒŒì¼: {file_stats['error_files']}ê°œ")
        print(f"ðŸ“ˆ ì´ ë°ì´í„° í¬ì¸íŠ¸: {len(combined_df):,}ê°œ")
        print(f"âš–ï¸ ë³´í–‰ ë¹„ìœ¨: {combined_df['label'].mean():.2%}")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶œë ¥
        memory_usage = combined_df.memory_usage(deep=True).sum() / 1024**2
        print(f"ðŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_usage:.1f} MB")
        
        return combined_df, file_stats
    else:
        print("âŒ ë¡œë”©ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, file_stats

# =============================================================================
# ê¸°ì¡´ ë°©ì‹ê³¼ ê°œì„ ëœ ë°©ì‹ ë¹„êµ
# =============================================================================

def compare_loading_methods():
    """ê¸°ì¡´ ì¶”ì¶œ ë°©ì‹ vs ì§ì ‘ ë¡œë”© ë°©ì‹ ë¹„êµ"""
    
    print("ðŸ”„ ë°ì´í„° ë¡œë”© ë°©ì‹ ë¹„êµ")
    print("="*50)
    
    comparison = {
        'êµ¬ë¶„': ['ê¸°ì¡´ ì¶”ì¶œ ë°©ì‹', 'ì§ì ‘ ë¡œë”© ë°©ì‹'],
        'ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰': ['2ë°° (ì›ë³¸ + ë³µì‚¬ë³¸)', '1ë°° (ì›ë³¸ë§Œ)'],
        'ì²˜ë¦¬ ì‹œê°„': ['ëŠë¦¼ (ë³µì‚¬ + ë¡œë”©)', 'ë¹ ë¦„ (ë¡œë”©ë§Œ)'],
        'ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±': ['ë‚®ìŒ (ì „ì²´ ë¡œë”©)', 'ë†’ìŒ (í•„ìš”í•œ ì»¬ëŸ¼ë§Œ)'],
        'ìœ ì—°ì„±': ['ë‚®ìŒ (ê³ ì •ëœ Task)', 'ë†’ìŒ (ë™ì  í•„í„°ë§)'],
        'ìœ ì§€ë³´ìˆ˜': ['ë³µìž¡ (2ë‹¨ê³„)', 'ê°„ë‹¨ (1ë‹¨ê³„)']
    }
    
    df = pd.DataFrame(comparison)
    print(df.to_string(index=False))
    
    print(f"\nðŸ’¡ ê¶Œìž¥ì‚¬í•­:")
    print(f"   â€¢ ì¼íšŒì„± ë¶„ì„: ì§ì ‘ ë¡œë”© ë°©ì‹ ì‚¬ìš©")
    print(f"   â€¢ ë°˜ë³µ ë¶„ì„: ì²« ì‹¤í–‰ì‹œ pickleë¡œ ì €ìž¥ í›„ ìž¬ì‚¬ìš©")
    print(f"   â€¢ ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ: ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬")

# =============================================================================
# ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì²­í¬ ì²˜ë¦¬
# =============================================================================

def load_data_in_chunks(base_path, chunk_size=10):
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬"""
    
    print(f"ðŸ”„ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ (ì²­í¬ í¬ê¸°: {chunk_size}ê°œ íŒŒì¼)")
    
    # ëª¨ë“  íŒŒì¼ ëª©ë¡ ë¨¼ì € ìˆ˜ì§‘
    all_files = []
    for subject_num in range(6, 39):
        if subject_num == 34:
            continue
        subject_id = f'SA{subject_num:02d}'
        subject_folder = os.path.join(base_path, subject_id)
        if os.path.exists(subject_folder):
            csv_files = glob.glob(os.path.join(subject_folder, '*.csv'))
            all_files.extend(csv_files)
    
    print(f"ðŸ“ ì´ {len(all_files)}ê°œ íŒŒì¼ ë°œê²¬")
    
    # ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    for i in range(0, len(all_files), chunk_size):
        chunk_files = all_files[i:i+chunk_size]
        print(f"ðŸ”„ ì²­í¬ {i//chunk_size + 1} ì²˜ë¦¬ ì¤‘... ({len(chunk_files)}ê°œ íŒŒì¼)")
        
        # ì²­í¬ ì²˜ë¦¬ ë¡œì§
        chunk_data = []
        for file_path in chunk_files:
            # íŒŒì¼ ì²˜ë¦¬ (ìœ„ì˜ ë¡œì§ê³¼ ë™ì¼)
            pass
        
        # ì²­í¬ë³„ ê²°ê³¼ ì²˜ë¦¬
        yield chunk_data

# =============================================================================
# ì‚¬ìš© ì˜ˆì‹œ
# =============================================================================

if __name__ == "__main__":
    print("ðŸš€ ê°œì„ ëœ ë°ì´í„° ë¡œë”© ì‹œìŠ¤í…œ")
    print("="*40)
    
    # ë°©ì‹ ë¹„êµ
    compare_loading_methods()
    
    print(f"\n" + "="*40)
    
    # ì‹¤ì œ ë¡œë”© (ì˜ˆì‹œ)
    # data, stats = load_data_directly_from_sensor()
    
    print(f"\nâœ… ê²°ë¡ :")
    print(f"   ê¸°ì¡´ ì¶”ì¶œ ë°©ì‹ ëŒ€ì‹  ì§ì ‘ ë¡œë”© ë°©ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”!")
    print(f"   - ë” ë¹ ë¥´ê³  íš¨ìœ¨ì ")
    print(f"   - ë””ìŠ¤í¬ ê³µê°„ ì ˆì•½") 
    print(f"   - ìœ ì—°í•œ í•„í„°ë§ ê°€ëŠ¥") 