# =============================================================================
# ë³´í–‰ ê°ì§€: ë¨¸ì‹ ëŸ¬ë‹ vs ê·œì¹™ ê¸°ë°˜ ì ‘ê·¼ë²• ë¹„êµ
# =============================================================================

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, f1_score
import joblib

# =============================================================================
# 1. ë¨¸ì‹ ëŸ¬ë‹ ì ‘ê·¼ë²•
# =============================================================================

class MLWalkingDetector:
    """ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ë³´í–‰ ê°ì§€ê¸°"""
    
    def __init__(self, model_type='random_forest'):
        self.model_type = model_type
        self.model = None
        self.feature_scaler = None
        
    def train(self, features_df):
        """ëª¨ë¸ í•™ìŠµ"""
        # íŠ¹ì§• ì„ íƒ
        feature_columns = [
            'acc_mean', 'acc_std', 'acc_range', 'gyr_mean', 'gyr_std',
            'step_frequency', 'step_regularity', 'peak_count', 'peak_density',
            'walking_energy_ratio'
        ]
        
        X = features_df[feature_columns]
        y = features_df['label']
        
        # í”¼í—˜ìë³„ ë¶„í• 
        subjects = features_df['subject_id'].unique()
        train_subjects, test_subjects = train_test_split(subjects, test_size=0.3, random_state=42)
        
        train_mask = features_df['subject_id'].isin(train_subjects)
        test_mask = features_df['subject_id'].isin(test_subjects)
        
        X_train, X_test = X[train_mask], X[test_mask]
        y_train, y_test = y[train_mask], y[test_mask]
        
        # ëª¨ë¸ ì„ íƒ ë° í•™ìŠµ
        if self.model_type == 'random_forest':
            self.model = RandomForestClassifier(n_estimators=100, random_state=42)
        elif self.model_type == 'svm':
            self.model = SVC(probability=True, random_state=42)
        elif self.model_type == 'neural_network':
            self.model = MLPClassifier(hidden_layer_sizes=(64, 32), random_state=42)
        
        # í•™ìŠµ
        self.model.fit(X_train, y_train)
        
        # ì„±ëŠ¥ í‰ê°€
        y_pred = self.model.predict(X_test)
        f1 = f1_score(y_test, y_pred)
        
        print(f"ğŸ¤– {self.model_type} ëª¨ë¸ ì„±ëŠ¥:")
        print(f"   F1 Score: {f1:.3f}")
        print(classification_report(y_test, y_pred))
        
        return f1
    
    def predict(self, features):
        """ì˜ˆì¸¡ (ì‹¤ì‹œê°„ ì‚¬ìš©)"""
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # íŠ¹ì§• ë²¡í„°ë¥¼ 2D ë°°ì—´ë¡œ ë³€í™˜
        if len(features.shape) == 1:
            features = features.reshape(1, -1)
        
        # ì˜ˆì¸¡
        probability = self.model.predict_proba(features)[0][1]  # ë³´í–‰ í™•ë¥ 
        prediction = self.model.predict(features)[0]
        
        return prediction, probability
    
    def save_model(self, filepath):
        """ëª¨ë¸ ì €ì¥"""
        joblib.dump(self.model, filepath)
    
    def load_model(self, filepath):
        """ëª¨ë¸ ë¡œë“œ"""
        self.model = joblib.load(filepath)

# =============================================================================
# 2. ê·œì¹™ ê¸°ë°˜ ì ‘ê·¼ë²• (ê¸°ì¡´ ë°©ì‹)
# =============================================================================

class RuleBasedWalkingDetector:
    """ê·œì¹™ ê¸°ë°˜ ë³´í–‰ ê°ì§€ê¸°"""
    
    def __init__(self, config):
        self.config = config
        
    def predict(self, features):
        """ì˜ˆì¸¡ (ì‹¤ì‹œê°„ ì‚¬ìš©)"""
        confidence = 0.0
        
        # ê°€ì†ë„ í‰ê·  ì²´í¬
        if (self.config['thresholds']['acc_mean_min'] <= features['acc_mean'] <= 
            self.config['thresholds']['acc_mean_max']):
            confidence += self.config['weights']['acc_mean_weight']
        
        # ê°€ì†ë„ í‘œì¤€í¸ì°¨ ì²´í¬
        if features['acc_std'] >= self.config['thresholds']['acc_std_min']:
            confidence += self.config['weights']['acc_std_weight']
        
        # ë³´í–‰ ì£¼íŒŒìˆ˜ ì²´í¬
        if (self.config['thresholds']['step_freq_min'] <= features['step_frequency'] <= 
            self.config['thresholds']['step_freq_max']):
            confidence += self.config['weights']['step_freq_weight']
        
        # ê·œì¹™ì„± ì²´í¬
        if features['step_regularity'] >= self.config['thresholds']['regularity_min']:
            confidence += self.config['weights']['regularity_weight']
        
        prediction = 1 if confidence >= self.config['thresholds']['confidence_min'] else 0
        
        return prediction, confidence

# =============================================================================
# 3. ì„±ëŠ¥ ë¹„êµ
# =============================================================================

def compare_approaches(features_df):
    """ë¨¸ì‹ ëŸ¬ë‹ vs ê·œì¹™ ê¸°ë°˜ ì„±ëŠ¥ ë¹„êµ"""
    
    print("ğŸ”¬ ë¨¸ì‹ ëŸ¬ë‹ vs ê·œì¹™ ê¸°ë°˜ ì ‘ê·¼ë²• ë¹„êµ")
    print("="*50)
    
    # 1. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë“¤ í…ŒìŠ¤íŠ¸
    ml_results = {}
    
    for model_type in ['random_forest', 'svm', 'neural_network']:
        print(f"\nğŸ¤– {model_type} í•™ìŠµ ì¤‘...")
        ml_detector = MLWalkingDetector(model_type)
        f1_score = ml_detector.train(features_df)
        ml_results[model_type] = f1_score
    
    # 2. ê·œì¹™ ê¸°ë°˜ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    print(f"\nğŸ“ ê·œì¹™ ê¸°ë°˜ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸...")
    
    # ì˜ˆì‹œ ì„¤ì • (ì‹¤ì œë¡œëŠ” optimal_threshold_analysis.py ê²°ê³¼ ì‚¬ìš©)
    rule_config = {
        'thresholds': {
            'acc_mean_min': 0.9,
            'acc_mean_max': 1.2,
            'acc_std_min': 0.2,
            'step_freq_min': 1.0,
            'step_freq_max': 4.0,
            'regularity_min': 0.4,
            'confidence_min': 0.6
        },
        'weights': {
            'acc_mean_weight': 0.25,
            'acc_std_weight': 0.25,
            'step_freq_weight': 0.35,
            'regularity_weight': 0.15
        }
    }
    
    rule_detector = RuleBasedWalkingDetector(rule_config)
    
    # ê·œì¹™ ê¸°ë°˜ ì„±ëŠ¥ ê³„ì‚°
    predictions = []
    for _, row in features_df.iterrows():
        pred, conf = rule_detector.predict(row)
        predictions.append(pred)
    
    rule_f1 = f1_score(features_df['label'], predictions)
    
    # ê²°ê³¼ ë¹„êµ
    print(f"\nğŸ“Š ì„±ëŠ¥ ë¹„êµ ê²°ê³¼:")
    print(f"   ê·œì¹™ ê¸°ë°˜:        F1 = {rule_f1:.3f}")
    for model, f1 in ml_results.items():
        print(f"   {model:15}: F1 = {f1:.3f}")
    
    return ml_results, rule_f1

# =============================================================================
# 4. ì‹¤ì‹œê°„ ì„±ëŠ¥ ë¹„êµ
# =============================================================================

def compare_realtime_performance():
    """ì‹¤ì‹œê°„ ì„±ëŠ¥ ë¹„êµ (ì†ë„, ë©”ëª¨ë¦¬ ë“±)"""
    
    print("\nâš¡ ì‹¤ì‹œê°„ ì„±ëŠ¥ ë¹„êµ:")
    print("="*30)
    
    comparison = {
        'êµ¬ë¶„': ['ê·œì¹™ ê¸°ë°˜', 'ëœë¤í¬ë ˆìŠ¤íŠ¸', 'SVM', 'ì‹ ê²½ë§'],
        'ì˜ˆì¸¡ ì†ë„': ['~0.1ms', '~1-5ms', '~0.5-2ms', '~2-10ms'],
        'ë©”ëª¨ë¦¬ ì‚¬ìš©': ['~1KB', '~100KB-1MB', '~10KB-100KB', '~1MB-10MB'],
        'ë°°í„°ë¦¬ ì˜í–¥': ['ìµœì†Œ', 'ë³´í†µ', 'ë³´í†µ', 'ë†’ìŒ'],
        'í•´ì„ ê°€ëŠ¥ì„±': ['ë†’ìŒ', 'ë³´í†µ', 'ë‚®ìŒ', 'ë‚®ìŒ'],
        'ì•ˆì •ì„±': ['ë†’ìŒ', 'ë†’ìŒ', 'ë³´í†µ', 'ë³´í†µ']
    }
    
    df = pd.DataFrame(comparison)
    print(df.to_string(index=False))
    
    print(f"\nğŸ’¡ ê²°ë¡ :")
    print(f"   â€¢ ë¼ì¦ˆë² ë¦¬íŒŒì´ ì‹¤ì‹œê°„ ê°ì§€: ê·œì¹™ ê¸°ë°˜ì´ ìµœì ")
    print(f"   â€¢ ë†’ì€ ì •í™•ë„ê°€ í•„ìš”í•œ ì—°êµ¬: ë¨¸ì‹ ëŸ¬ë‹ ê³ ë ¤")
    print(f"   â€¢ ë°°í„°ë¦¬ ìˆ˜ëª… ì¤‘ìš”: ê·œì¹™ ê¸°ë°˜ ì„ íƒ")

# =============================================================================
# ì‚¬ìš© ì˜ˆì‹œ
# =============================================================================

if __name__ == "__main__":
    # ê°€ìƒì˜ íŠ¹ì§• ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    # ì‹¤ì œë¡œëŠ” optimal_threshold_analysis.pyì˜ features_df ì‚¬ìš©
    
    print("ğŸ¯ ë³´í–‰ ê°ì§€ ì ‘ê·¼ë²• ë¹„êµ ë¶„ì„")
    print("="*40)
    
    # ì‹¤ì œ ì‚¬ìš©ì‹œì—ëŠ” ë‹¤ìŒê³¼ ê°™ì´:
    # features_df = extract_windowed_features(data)
    # ml_results, rule_f1 = compare_approaches(features_df)
    
    compare_realtime_performance()
    
    print(f"\nâœ… ê²°ë¡ : í˜„ì¬ êµ¬í˜„ì€ 'í†µê³„ì  ìµœì í™”ëœ ê·œì¹™ ê¸°ë°˜ ì‹œìŠ¤í…œ'ì…ë‹ˆë‹¤!")
    print(f"   ë¨¸ì‹ ëŸ¬ë‹ì´ ì•„ë‹Œ, ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ìµœì í™”ëœ if-else ê·œì¹™ë“¤ì…ë‹ˆë‹¤.") 